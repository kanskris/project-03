{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the file\n",
    "df = pd.read_json (r'VEEV.json')\n",
    "\n",
    "#print the head\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t'] = pd.to_datetime(df['t'], unit='s')\n",
    "df = df.rename(columns={'c': 'Close', 'h': 'High', 'l':'Low',  'o': 'Open', 's': 'Status', 't': 'Date', 'v': 'Volume'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the file\n",
    "df = pd.read_json (r'VEEV.json')\n",
    "\n",
    "#print the head\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t'] = pd.to_datetime(df['t'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['t']]\n",
    "y = df['c'].values.reshape(-1, 1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X.copy()\n",
    "\n",
    "data_binary_encoded = pd.get_dummies(data)\n",
    "data_binary_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "clf_lr = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "plt.scatter(model.predict(X_train_scaled), model.predict(X_train_scaled) - y_train_scaled, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test_scaled), model.predict(X_test_scaled) - y_test_scaled, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_scaled.min(), xmax=y_test_scaled.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_scaled)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['mon_fri'] = 0\n",
    "for i in range(0,len(new_data)):\n",
    "    if (new_data['Dayofweek'][i] == 0 or new_data['Dayofweek'][i] == 4):\n",
    "        new_data['mon_fri'][i] = 1\n",
    "    else:\n",
    "        new_data['mon_fri'][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and validation\n",
    "train = new_data[:987]\n",
    "valid = new_data[987:]\n",
    "\n",
    "x_train = train.drop('Close', axis=1)\n",
    "y_train = train['Close']\n",
    "x_valid = valid.drop('Close', axis=1)\n",
    "y_valid = valid['Close']\n",
    "\n",
    "#implement linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions and find the rmse\n",
    "preds = model.predict(X_test_scaled)\n",
    "rms=np.sqrt(np.mean(np.power((np.array(y_test_scaled)-np.array(preds)),2)))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = model.score(X_test_scaled, y_test_scaled)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "valid['Predictions'] = 0\n",
    "valid['Predictions'] = preds\n",
    "\n",
    "valid.index = new_data[987:].index\n",
    "train.index = new_data[:987].index\n",
    "\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close', 'Predictions']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the file\n",
    "df = pd.read_json (r'VEEV.json')\n",
    "\n",
    "#print the head\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t'] = pd.to_datetime(df['t'], unit='s')\n",
    "df = df.rename(columns={'c': 'Close', 'h': 'High', 'l':'Low',  'o': 'Open', 's': 'Status', 't': 'Date', 'v': 'Volume'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor variables\n",
    "df['Open-Close']= df.Open -df.Close\n",
    "df['High-Low']  = df.High - df.Low\n",
    "df =df.dropna()\n",
    "X= df[['Open-Close', 'High-Low']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable\n",
    "Y= np.where(df['Close'].shift(-1)>df['Close'],1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "split_percentage = 0.7\n",
    "split = int(split_percentage*len(df))\n",
    "\n",
    "X_train = X[:split]\n",
    "Y_train = Y[:split]\n",
    "\n",
    "X_test = X[split:]\n",
    "Y_test = Y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 50, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    train_score = knn.score(X_train, Y_train)\n",
    "    test_score = knn.score(X_test, Y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 50, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 50, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate KNN learning model(k=15)\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "# fit the model\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "# Accuracy Score\n",
    "accuracy_train = accuracy_score(Y_train, knn.predict(X_train))\n",
    "accuracy_test = accuracy_score(Y_test, knn.predict(X_test))\n",
    "\n",
    "print ('Train_data Accuracy: %.2f' %accuracy_train)\n",
    "print ('Test_data Accuracy: %.2f' %accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Prediction\": pred, 'Actual': Y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted Signal\n",
    "df['Predicted_Signal'] = knn.predict(X)\n",
    "\n",
    "# SPY Cumulative Returns\n",
    "df['SPY_returns'] = np.log(df['Close']/df['Close'].shift(1))\n",
    "Cumulative_SPY_returns = df[split:]['SPY_returns'].cumsum()*100\n",
    "\n",
    "# Cumulative Strategy Returns \n",
    "df['Startegy_returns'] = df['SPY_returns']* df['Predicted_Signal'].shift(1)\n",
    "Cumulative_Strategy_returns = df[split:]['Startegy_returns'].cumsum()*100\n",
    "\n",
    "# Plot the results to visualize the performance\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(Cumulative_SPY_returns, color='r',label = 'SPY Returns')\n",
    "plt.plot(Cumulative_Strategy_returns, color='g', label = 'Strategy Returns')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Sharpe Ratio?\n",
    "Sharpe ratio is a measure for calculating risk-adjusted return. It is the ratio of the excess expected return of investment (over risk-free rate) per unit of volatility or standard deviation.\n",
    "\n",
    "Let us see the formula for Sharpe ratio which will make things much clearer. The sharpe ratio calculation is done in the following manner\n",
    "\n",
    "Sharpe Ratio = (Rx – Rf) / StdDev(x)\n",
    "\n",
    "Where,\n",
    "x is the investment\n",
    "Rx is the average rate of return of x\n",
    "Rf is the risk-free rate of return\n",
    "StdDev(x) is the standard deviation of Rx\n",
    "Once you see the formula, you will understand that we deduct the risk-free rate of return as this helps us in figuring out if the strategy makes sense or not. If the Numerator turned out negative, wouldn’t it be better to invest in a government bond which guarantees you a risk-free rate of return? Some of you would recognise this as the risk-adjusted return.\n",
    "\n",
    "In the denominator, we have the standard deviation of the average return of the investment. It helps us in identifying the volatility as well as the risk associated with the investment.\n",
    "\n",
    "Thus, the Sharpe ratio helps us in identifying which strategy gives better returns in comparison to the volatility. There, that is all when it comes to sharpe ratio calculation.\n",
    "\n",
    "Let’s take an example now to see how the Sharpe ratio calculation helps us.\n",
    "\n",
    "You have devised a strategy and created a portfolio of different stocks. After backtesting, you observe that this portfolio, let’s call it Portfolio A, will give a return of 11%. However, you are concerned with the volatility at 8%. \n",
    "\n",
    "Now, you change certain parameters and pick different financial instruments to create another portfolio, Portfolio B. This portfolio gives an expected return of 8%, but the volatility now drops to 4%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Sharpe reatio\n",
    "Std = Cumulative_Strategy_returns.std()\n",
    "Sharpe = (Cumulative_Strategy_returns-Cumulative_SPY_returns)/Std\n",
    "Sharpe = Sharpe.mean()\n",
    "print ('Sharpe ratio: %.2f'%Sharpe )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tested many neighbours and the lowest sharpe ratio was for 17."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import lag_plot\n",
    "from pandas import datetime\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the file\n",
    "df = pd.read_json (r'VEEV.json')\n",
    "\n",
    "#print the head\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "lag_plot(df['c'], lag=5)\n",
    "plt.title('Microsoft Autocorrelation plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df[0:int(len(df)*0.8)], df[int(len(df)*0.8):]\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.title('Microsoft Prices')\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Prices')\n",
    "plt.plot(df['c'], 'blue', label='Training Data')\n",
    "plt.plot(test_data['c'], 'green', label='Testing Data')\n",
    "plt.xticks(np.arange(0,size, 300), df['t'][0:size:300])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_kun(y_true, y_pred):\n",
    "    return np.mean((np.abs(y_pred - y_true) * 200/ (np.abs(y_pred) +       np.abs(y_true))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ar = train_data['c'].values\n",
    "test_ar = test_data['c'].values\n",
    "history = [x for x in train_ar]\n",
    "print(type(history))\n",
    "predictions = list()\n",
    "for t in range(len(test_ar)):\n",
    "    model = ARIMA(history, order=(5,1,0))\n",
    "    model_fit = model.fit(disp=0)\n",
    "    output = model_fit.forecast()\n",
    "    yhat = output[0]\n",
    "    predictions.append(yhat)\n",
    "    obs = test_ar[t]\n",
    "    history.append(obs)\n",
    "error = mean_squared_error(test_ar, predictions)\n",
    "print('Testing Mean Squared Error: %.3f' % error)\n",
    "error2 = smape_kun(test_ar, predictions)\n",
    "print('Symmetric mean absolute percentage error: %.3f' % error2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Prediction\": predictions, 'Actual': test_ar})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(df['c'], 'green', color='blue', label='Training Data')\n",
    "plt.plot(test_data.index, predictions, color='green', marker='o', linestyle='dashed', \n",
    "         label='Predicted Price')\n",
    "plt.plot(test_data.index, test_data['c'], color='red', label='Actual Price')\n",
    "plt.title('Microsoft Prices Prediction')\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Prices')\n",
    "plt.xticks(np.arange(0,size, 1300), df['t'][0:size:1300])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the file\n",
    "df = pd.read_json (r'VEEV.json')\n",
    "\n",
    "#print the head\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t'] = pd.to_datetime(df['t'], unit='s')\n",
    "df = df.rename(columns={'c': 'Close', 'h': 'High', 'l':'Low',  'o': 'Open', 's': 'Status', 't': 'Date', 'v': 'Volume'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(df)\n",
    "tsize = int(size/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing prophet\n",
    "from fbprophet import Prophet\n",
    "\n",
    "#creating dataframe\n",
    "new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    new_data['Date'][i] = df['Date'][i]\n",
    "    new_data['Close'][i] = df['Close'][i]\n",
    "\n",
    "new_data['Date'] = pd.to_datetime(new_data.Date,format='%Y-%m-%d')\n",
    "new_data.index = new_data['Date']\n",
    "\n",
    "#preparing data\n",
    "new_data.rename(columns={'Close': 'y', 'Date': 'ds'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and validation\n",
    "train = new_data[:tsize]\n",
    "valid = new_data[tsize:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "model = Prophet()\n",
    "model.fit(train)\n",
    "\n",
    "#predictions\n",
    "close_prices = model.make_future_dataframe(periods=len(valid))\n",
    "forecast = model.predict(close_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_prices.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse\n",
    "forecast_valid = forecast['yhat'][tsize:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forecast_valid.shape, valid['y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms=np.sqrt(np.mean(np.power((np.array(valid['y'])-np.array(forecast_valid)),2)))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid['yhat'] = forecast['yhat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "valid['Predictions'] = 0\n",
    "valid['Predictions'] = forecast_valid.values\n",
    "\n",
    "plt.plot(train['y'])\n",
    "plt.plot(valid[['y', 'Predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Prediction\": valid['Predictions'], \"Actual\": valid['y']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of Linear Regerssion Model:\",clf_lr.score(x_test,y_test))\n",
    "print(\"Accuracy of KNN Model:%.2f' %accuracy_test)\n",
    "print(\"Accuracy of Auto ARIMA Model:\",clf_aa.score(x_test,y_test))\n",
    "print(\"Accuracy of Gradient Boosting Model:\",clf_p.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
